agent_class: CLASVAEAgent

agent_0:
  actor_observations: [
    [robot0_proprio-state, 43], #(39,)
    [robot1_proprio-state, 43]
  ]
  critic_observations: [
    [robot0_proprio-state, 43], #(39,)
    [robot1_proprio-state, 43]
  ]

clas_training:
  vae_config: {
                'latent_dim': 8,
                'hidden_dim': 256,
                'vae_batch_size': 256,
                'vae_buffer_size': 400000,
                'vae_buffer_train_prefill_size': 100000,
                'vae_buffer_eval_prefill_size': 10000,
                'vae_updates': 100000,
                'vae_train_freq': 1,
                'max_episode_steps': 500,
                'lr': 3e-5,
                'vae_train_freq': 4,           # Train VAE every 4 SAC updates
                'vae_updates_per_step': 1,     # Number of VAE updates per training step
            }
  
  sac_config: {
            'gamma': 0.99,
            'tau': 0.005,
            'alpha': 0.25,
            'lr': 5e-4,
            'buffer_size': 1000000,
            'batch_size': 256,
            'start_steps': 10000,
            'num_episodes': 1000
        }

kwargs: 
  normalize_observations: true
  num_transitions_per_env: 1000 #How many transitions to collect per rollout. 